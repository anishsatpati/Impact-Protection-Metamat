{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import random\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "wDr = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wDr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initilaise the model\n",
    "forward_model = SimpleMLP(5, 2).to(device)\n",
    "\n",
    "# Load the saved model weights\n",
    "forward_model.load_state_dict(torch.load(wDr + r\"\\forward_model_weights_5000_iteration0.pth\"))\n",
    "\n",
    "# Evaluate each model\n",
    "forward_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.read_csv(wDr + r\"\\Final_dataset.csv\")\n",
    "#concatenated_df.set_index(['index'], inplace = True)\n",
    "concatenated_df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "#concatenated_df = concatenated_df[-35:]\n",
    "concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = concatenated_df.iloc[:, :5].values\n",
    "Y = concatenated_df.iloc[:, 5:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['PS'] = Y[:, 0]\n",
    "df['SED'] = Y[:, 1]\n",
    "df['theta_min'] = X[:, 0]\n",
    "df['theta_max'] = X[:, 1]\n",
    "df['t_min'] = X[:, 2]\n",
    "df['t_max'] = X[:, 3]\n",
    "df['velocity'] = X[:, 4]\n",
    "df = df.round(6)\n",
    "#df['velocity'].unique()\n",
    "\n",
    "df['sigma_minus_U'] = df['PS'] - 10*df['SED']\n",
    "df.sort_values('sigma_minus_U', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['SED'], df['sigma_minus_U'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['PS'], df['sigma_minus_U'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prime = df.groupby('t_min').sum().round(5)\n",
    "df_prime = df_prime.sort_values(['sigma_minus_U'])\n",
    "df_prime.reset_index(inplace= True)\n",
    "df_prime = df_prime[['PS', 'SED', 'theta_min', 'theta_max', 't_min', 't_max', 'velocity', 'sigma_minus_U']]\n",
    "df_prime = df_prime.iloc[:50]\n",
    "df_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given ordered column values\n",
    "ordered_values = df_prime['t_min']\n",
    "\n",
    "# Sort DataFrame based on the order of values in column 'B'\n",
    "df_sorted = df.set_index('t_min').loc[ordered_values].reset_index()\n",
    "\n",
    "df_sorted = df_sorted[df_sorted['velocity'] == 1]\n",
    "\n",
    "# Define the desired column order\n",
    "column_order = ['PS', 'SED', 'theta_min', 'theta_max', 't_min', 't_max', 'velocity', 'sigma_minus_U']\n",
    "\n",
    "# Reorder the columns\n",
    "df = df_sorted[column_order]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix relative density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independant parameters\n",
    "Platelength_X = 150.0\n",
    "Platelength_Y = 100.0\n",
    "type1 = 2\n",
    "height = 2\n",
    "\n",
    "# Dependant parameters\n",
    "L = Platelength_X/type1/5\n",
    "B = Platelength_Y/type1/2\n",
    "\n",
    "LHS = 1153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your analytical expression\n",
    "def analytical_expression(theta_min, theta_max, t_min, t_max):\n",
    "    \n",
    "    #t = torch.linspace(t_min, t_max, 2*type1 + 1)\n",
    "    #theta = torch.linspace(theta_min, theta_max, 2*type1)\n",
    "\n",
    "    steps = 2*type1 + 1\n",
    "    index = torch.arange(steps, dtype=torch.float32).to(device)\n",
    "    step_size = (t_max - t_min) / (steps - 1)\n",
    "    t = t_min + step_size * index\n",
    "\n",
    "    steps = 2*type1\n",
    "    index = torch.arange(steps, dtype=torch.float32).to(device)\n",
    "    step_size = (theta_max - theta_min) / (steps - 1)\n",
    "    theta = theta_min + step_size * index\n",
    "\n",
    "    RHS = 0\n",
    "    for i in range(len(t) - 1):  \n",
    "        #t_inside = torch.linspace(t[i], t[i+1], 4)\n",
    "\n",
    "        steps = 4\n",
    "        index = torch.arange(steps, dtype=torch.float32).to(device)\n",
    "        step_size = (t[i+1] - t[i]) / (steps - 1)\n",
    "        t_inside = t[i] + step_size * index\n",
    "\n",
    "        tan_alpha = (2 - torch.abs(torch.cos(theta[i])))/torch.sin(theta[i])\n",
    "        \n",
    "        RHS += torch.abs(torch.cos(theta[i]))/(4 * torch.sin(theta[i])) * ((L - t_inside[1])**2 + (L - t_inside[2])**2 + (L - t[i])**2 + (L - t[i+1])**2) + height * ((L - t[i]) + (L - t[i+1])) + 0.5 * ((L - t_inside[1]) + (L - t_inside[2])) * (B - 2*height - torch.abs(torch.cos(theta[i]))/(2*torch.sin(theta[i])) * ((L - t_inside[1]) + (L - t_inside[2])) - tan_alpha * (t_inside[1]/2 + t_inside[2]/2))\n",
    "\n",
    "    return RHS\n",
    "\n",
    "# Define the objective function\n",
    "def rho_objective(params, target_value):\n",
    "\n",
    "    theta_min = params[0]\n",
    "    theta_max = params[1]\n",
    "    t_min = params[2]\n",
    "    t_max = params[3]\n",
    "\n",
    "    return abs(analytical_expression(theta_min, theta_max, t_min, t_max) - target_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_pred, SED_pred = 0, 0\n",
    "good = []\n",
    "\n",
    "while len(good) < 5:\n",
    "    # Define upper and lower bounds for lattice parameters\n",
    "    lower_bounds = [np.pi/4, np.pi/4, 0.5, 0.5]  # Lower bounds for each parameter\n",
    "    upper_bounds = [np.pi/2, np.pi/2, 3, 3]  # Upper bounds for each parameter\n",
    "\n",
    "\n",
    "\n",
    "    # Step 1: Create the fitness function and individual\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))  # Minimization problem (minimizing the difference)\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Step 2: Initialize population and individual with 4 parameters from DataFrame, respecting bounds\n",
    "    def create_individual(index):\n",
    "        #individual = list(df.iloc[index, 2:6].round(6))  # Select lattice parameters from columns 3 to 6\n",
    "        individual = list(df.iloc[index, 2:6].round(6))  # Select lattice parameters from columns 3 to 6\n",
    "        return individual\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    #toolbox.register(\"individual\", tools.initIterate, creator.Individual, lambda: create_individual(index))\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual, lambda: create_individual(random.randint(0, len(df)-1)))\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Step 3: Define evaluation function (difference between the first two columns)\n",
    "    def evaluate(individual):\n",
    "        # Find the index in the DataFrame that corresponds to the individual (assuming exact match)\n",
    "        v1 = torch.tensor([0], dtype=torch.float32).to(device)\n",
    "        v2 = torch.tensor([0.137931], dtype=torch.float32).to(device)\n",
    "        v3 = torch.tensor([0.310345], dtype=torch.float32).to(device)\n",
    "        v4 = torch.tensor([0.482759], dtype=torch.float32).to(device)\n",
    "        v5 = torch.tensor([0.655172], dtype=torch.float32).to(device)\n",
    "        v6 = torch.tensor([0.827586], dtype=torch.float32).to(device)\n",
    "        v7 = torch.tensor([1], dtype=torch.float32).to(device)\n",
    "\n",
    "        lattice_params = torch.tensor(individual, dtype=torch.float32).to(device)\n",
    "        #lattice_params = torch.clamp(lattice_params, torch.tensor(lower_bounds, dtype = torch.float32).to(device), torch.tensor(upper_bounds, dtype = torch.float32).to(device))\n",
    "        #print(lattice_params)\n",
    "\n",
    "        tensor1 = torch.concat((lattice_params, v1))\n",
    "        tensor2 = torch.concat((lattice_params, v2))\n",
    "        tensor3 = torch.concat((lattice_params, v3))\n",
    "        tensor4 = torch.concat((lattice_params, v4))\n",
    "        tensor5 = torch.concat((lattice_params, v5))\n",
    "        tensor6 = torch.concat((lattice_params, v6))\n",
    "        tensor7 = torch.concat((lattice_params, v7))\n",
    "        \n",
    "        outputs1 = forward_model(tensor1).detach().cpu().numpy()\n",
    "        outputs2 = forward_model(tensor2).detach().cpu().numpy()\n",
    "        outputs3 = forward_model(tensor3).detach().cpu().numpy()\n",
    "        outputs4 = forward_model(tensor4).detach().cpu().numpy()\n",
    "        outputs5 = forward_model(tensor5).detach().cpu().numpy()\n",
    "        outputs6 = forward_model(tensor6).detach().cpu().numpy()\n",
    "        outputs7 = forward_model(tensor7).detach().cpu().numpy()\n",
    "\n",
    "        return (outputs1[0] - 10*outputs1[1] + outputs2[0] - 10*outputs2[1] + outputs3[0] - 10*outputs3[1] + outputs4[0] - 10*outputs4[1] +\n",
    "                    outputs5[0] - 10*outputs5[1] + outputs6[0] - 10*outputs6[1] + outputs7[0] - 10*outputs7[1] + rho_objective(lattice_params, LHS),)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Step 4: Define bounded mutation to keep individuals within bounds\n",
    "    def bounded_mutate(individual, mu, sigma, indpb):\n",
    "        for i in range(len(individual)):\n",
    "            if random.random() < indpb:\n",
    "                individual[i] += random.gauss(mu, sigma)\n",
    "                # Apply bounds to each parameter\n",
    "                individual[i] = min(max(individual[i], lower_bounds[i]), upper_bounds[i])\n",
    "        return individual,\n",
    "\n",
    "    def apply_bounds(individual, lower_bounds, upper_bounds):\n",
    "        return [min(max(ind, lb), ub) for ind, lb, ub in zip(individual, lower_bounds, upper_bounds)]\n",
    "\n",
    "    def crossover_and_clamp(ind1, ind2, alpha=0.5):\n",
    "        tools.cxBlend(ind1, ind2, alpha)\n",
    "        ind1[:] = apply_bounds(ind1, lower_bounds, upper_bounds)\n",
    "        ind2[:] = apply_bounds(ind2, lower_bounds, upper_bounds)\n",
    "        return ind1, ind2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Step 5: Register genetic operators\n",
    "    #toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)  # Blend crossover\n",
    "    toolbox.register(\"mate\", crossover_and_clamp)\n",
    "    toolbox.register(\"mutate\", bounded_mutate, mu=0, sigma=0.2, indpb=0.2)  # Bounded mutation\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)  # Tournament selection\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Step 6: Define genetic algorithm parameters\n",
    "    population_size = 50  # Size of the population\n",
    "    num_generations = 50  # Number of generations\n",
    "    cx_prob = 0.9  # Crossover probability\n",
    "    mut_prob = 0 #0.2  # Mutation probability\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Step 7: Run the Genetic Algorithm\n",
    "\n",
    "    # Initialize population\n",
    "    #population = toolbox.population(n=population_size)\n",
    "    population = [creator.Individual(create_individual(i)) for i in range(len(df))]\n",
    "\n",
    "    # Statistics to track progress\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", lambda pop: sum(fitness[0] for fitness in pop) / len(pop))\n",
    "    stats.register(\"min\", lambda pop: min(fitness[0] for fitness in pop))\n",
    "    stats.register(\"max\", lambda pop: max(fitness[0] for fitness in pop))\n",
    "\n",
    "    # Run the genetic algorithm\n",
    "    #population, logbook = algorithms.eaSimple(population, toolbox, cxpb=cx_prob, mutpb=mut_prob,\n",
    "        #                                           ngen=num_generations, stats=stats, verbose=True)\n",
    "\n",
    "\n",
    "    # Custom loop to store best individual each generation\n",
    "    best_individuals_per_gen = []\n",
    "\n",
    "    # Initialize lists to store fitness values for each generation\n",
    "    min_fitness_values = []\n",
    "    max_fitness_values = []\n",
    "    avg_fitness_values = []\n",
    "\n",
    "    for gen in range(num_generations):\n",
    "\n",
    "        # Perform one generation\n",
    "        offspring = algorithms.varAnd(population, toolbox, cxpb=cx_prob, mutpb=mut_prob)\n",
    "        fits = list(map(toolbox.evaluate, offspring))\n",
    "        for fit, ind in zip(fits, offspring):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # Select the next generation population\n",
    "        population = toolbox.select(offspring, k=len(population))\n",
    "\n",
    "        # Calculate fitness statistics\n",
    "        min_fitness = min(ind.fitness.values[0].cpu() for ind in population)\n",
    "        max_fitness = max(ind.fitness.values[0].cpu() for ind in population)\n",
    "        avg_fitness = sum(ind.fitness.values[0].cpu() for ind in population) / len(population)\n",
    "\n",
    "        # Store fitness statistics for plotting later\n",
    "        min_fitness_values.append(min_fitness)\n",
    "        max_fitness_values.append(max_fitness)\n",
    "        avg_fitness_values.append(avg_fitness)\n",
    "\n",
    "        # Get the best individual of the current generation\n",
    "        best_individual = tools.selBest(population, k=1)[0]\n",
    "        best_individuals_per_gen.append(best_individual)\n",
    "\n",
    "        # Print best individual and fitness\n",
    "        #print(f\"Generation {gen}: Best Individual = {best_individual}, Fitness = {best_individual.fitness.values[0]}\")\n",
    "\n",
    "    # Save the best individuals from each generation\n",
    "    best_individuals_df = pd.DataFrame([list(ind) for ind in best_individuals_per_gen])\n",
    "    best_individuals_df.to_csv(\"best_individuals_per_gen\" + str(gen) + \".csv\", index=False)\n",
    "\n",
    "\n",
    "    # Output the best individual found\n",
    "    best_individual = tools.selBest(population, k=10)\n",
    "\n",
    "    optimized_params = pd.DataFrame(np.array(best_individual))\n",
    "\n",
    "    lattice_params = torch.tensor(best_individual, dtype=torch.float32).to(device)\n",
    "\n",
    "    good.append(lattice_params)\n",
    "\n",
    "# Plot the fitness values for each generation\n",
    "fig, ax = plt.subplots()\n",
    "#plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Adjust tick font sizes\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)  # Change fontsize for major ticks\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)  # Optional: Change fontsize for minor ticks\n",
    "\n",
    "# Remove the top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "plt.plot(range(num_generations), min_fitness_values, label=\"Min Fitness\", color='red')\n",
    "plt.plot(range(num_generations), max_fitness_values, label=\"Max Fitness\", color='green')\n",
    "plt.plot(range(num_generations), avg_fitness_values, label=\"Avg Fitness\", color='blue')\n",
    "plt.xlabel(\"Generation\", fontsize = 14, fontweight='bold')\n",
    "plt.ylabel(\"Fitness\", fontsize = 14, fontweight='bold')\n",
    "#plt.title(\"Fitness Evolution Over Generations\")\n",
    "plt.legend()\n",
    "#plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_pred1, SED_pred1, PS_pred2, SED_pred2, PS_pred3, SED_pred3, PS_pred4, SED_pred4, PS_pred5, SED_pred5, PS_pred6, SED_pred6, PS_pred7, SED_pred7 = [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "\n",
    "for lattice in good:\n",
    "    for lat in lattice:\n",
    "        forward_model.eval()\n",
    "\n",
    "        v1 = torch.tensor([0], dtype=torch.float32).to(device)\n",
    "        v2 = torch.tensor([0.137931], dtype=torch.float32).to(device)\n",
    "        v3 = torch.tensor([0.310345], dtype=torch.float32).to(device)\n",
    "        v4 = torch.tensor([0.482759], dtype=torch.float32).to(device)\n",
    "        v5 = torch.tensor([0.655172], dtype=torch.float32).to(device)\n",
    "        v6 = torch.tensor([0.827586], dtype=torch.float32).to(device)\n",
    "        v7 = torch.tensor([1], dtype=torch.float32).to(device)\n",
    "\n",
    "        lattice_params = torch.tensor(lat, dtype=torch.float32).to(device)\n",
    "\n",
    "        tensor1 = torch.concat((lattice_params, v1))\n",
    "        tensor2 = torch.concat((lattice_params, v2))\n",
    "        tensor3 = torch.concat((lattice_params, v3))\n",
    "        tensor4 = torch.concat((lattice_params, v4))\n",
    "        tensor5 = torch.concat((lattice_params, v5))\n",
    "        tensor6 = torch.concat((lattice_params, v6))\n",
    "        tensor7 = torch.concat((lattice_params, v7))\n",
    "        \n",
    "        PS1, SED1 = forward_model(tensor1)\n",
    "        PS2, SED2 = forward_model(tensor2)\n",
    "        PS3, SED3 = forward_model(tensor3)\n",
    "        PS4, SED4 = forward_model(tensor4)\n",
    "        PS5, SED5 = forward_model(tensor5)\n",
    "        PS6, SED6 = forward_model(tensor6)\n",
    "        PS7, SED7 = forward_model(tensor7)\n",
    "\n",
    "        PS_pred1.append(PS1.detach().cpu().numpy())\n",
    "        SED_pred1.append(SED1.detach().cpu().numpy())\n",
    "\n",
    "        PS_pred2.append(PS2.detach().cpu().numpy())\n",
    "        SED_pred2.append(SED2.detach().cpu().numpy())\n",
    "\n",
    "        PS_pred3.append(PS3.detach().cpu().numpy())\n",
    "        SED_pred3.append(SED3.detach().cpu().numpy())\n",
    "\n",
    "        PS_pred4.append(PS4.detach().cpu().numpy())\n",
    "        SED_pred4.append(SED4.detach().cpu().numpy())\n",
    "\n",
    "        PS_pred5.append(PS5.detach().cpu().numpy())\n",
    "        SED_pred5.append(SED5.detach().cpu().numpy())\n",
    "\n",
    "        PS_pred6.append(PS6.detach().cpu().numpy())\n",
    "        SED_pred6.append(SED6.detach().cpu().numpy())\n",
    "\n",
    "        PS_pred7.append(PS7.detach().cpu().numpy())\n",
    "        SED_pred7.append(SED7.detach().cpu().numpy())\n",
    "        #print(PS, SED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(PS_pred1, SED_pred1, s=10, color = 'brown')\n",
    "plt.scatter(PS_pred2, SED_pred2, s=10, color = 'cyan')\n",
    "plt.scatter(PS_pred3, SED_pred3, s=10, color = 'blue')\n",
    "plt.scatter(PS_pred4, SED_pred4, s=10, color = 'red')\n",
    "plt.scatter(PS_pred5, SED_pred5, s=10, color = 'indigo')\n",
    "plt.scatter(PS_pred6, SED_pred6, s=10, color = 'green')\n",
    "plt.scatter(PS_pred7, SED_pred7, s=10, color = 'black')\n",
    "\n",
    "plt.xlim(0, 6)\n",
    "plt.ylim(0, 0.8)\n",
    "#plt.legend(['v = 15', 'v = 20', 'v = 25'])\n",
    "#plt.savefig('optimized1_dynamic.png', transparent = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(good)):\n",
    "    good[i] = good[i].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_list = [arr[0].reshape(4) for arr in good]\n",
    "reshaped_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_params = optimized_params.drop_duplicates(subset=[0, 1, 2, 3])\n",
    "optimized_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimized_params.to_csv('gradient_optimized_structures_multi_speed_Dynamic_iteration0.csv', header = None, index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
