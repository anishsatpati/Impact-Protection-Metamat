{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "wDr = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in dynamic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.read_csv(wDr + r\"\\Final_dataset.csv\")\n",
    "concatenated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the velocity column\n",
    "concatenated_df['velocity'] = scaler.fit_transform(concatenated_df[['velocity']])\n",
    "concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean\n",
    "mean = concatenated_df.mean()\n",
    "\n",
    "# Calculate median\n",
    "median = concatenated_df.median()\n",
    "\n",
    "# Calculate mode\n",
    "mode = concatenated_df.mode().iloc[0]  # mode() can return multiple values, so take the first one\n",
    "\n",
    "# Calculate min\n",
    "min_val = concatenated_df.min()\n",
    "\n",
    "# Calculate max\n",
    "max_val = concatenated_df.max()\n",
    "\n",
    "# Combine all statistics into a single DataFrame\n",
    "stats = pd.DataFrame({\n",
    "    'Mean': mean,\n",
    "    'Median': median,\n",
    "    'Mode': mode,\n",
    "    'Min': min_val,\n",
    "    'Max': max_val\n",
    "})\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_column1 = concatenated_df['theta_min'].nunique()\n",
    "num_unique_column2 = concatenated_df['theta_max'].nunique()\n",
    "print(num_unique_column1, num_unique_column2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round theta values to 4 decimal places\n",
    "concatenated_df['theta_min'] = concatenated_df['theta_min'].astype(float).round(4)\n",
    "concatenated_df['theta_max'] = concatenated_df['theta_max'].astype(float).round(4)\n",
    "concatenated_df = concatenated_df.apply(lambda col: col.astype(float) if col.dtypes == 'object' else col)\n",
    "column_types = concatenated_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataset\n",
    "plt.scatter(concatenated_df['Peak Stress (MPa)'], concatenated_df['Strain Energy Density (MPa)'])\n",
    "plt.xlabel('Peak Stress (MPa)')\n",
    "plt.ylabel('Strain Energy Density (MPa)')\n",
    "plt.xlim(0, 7)\n",
    "plt.ylim(0, 0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histograms for columns 'A' and 'B'\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(concatenated_df['Peak Stress (MPa)'], bins=10, color='blue', edgecolor='black')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Peak Stress')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(concatenated_df['Strain Energy Density (MPa)'], bins=10, color='red', edgecolor='black')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Strain Energy Density')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = concatenated_df.iloc[:, :5].values\n",
    "Y = concatenated_df.iloc[:, 5:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "#concatenated_df.to_csv('Data_iteration0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate X and Y\n",
    "data = np.concatenate((X, Y), axis=1)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=[f\"X{i}\" for i in range(X.shape[1])] + [f\"Y{j}\" for j in range(Y.shape[1])])\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap between Inputs and Outputs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and remaining (which includes validation and test)\n",
    "X_train, X_remaining, Y_train, Y_remaining = train_test_split(X, Y, test_size=0.3, random_state=seed, shuffle=True)\n",
    "\n",
    "# Splitting remaining data into validation and test sets (50% each of the remaining 30%)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_remaining, Y_remaining, test_size=0.5, random_state=seed, shuffle=True)\n",
    "\n",
    "# Check if GPU is available and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32).to(device)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "Y_val_tensor = torch.tensor(Y_val, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define the neural network\n",
    "input_size = X_train.shape[1]\n",
    "output_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "forward_model = SimpleMLP(input_size, output_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.L1Loss()\n",
    "#optimizer = optim.Adam(forward_model.parameters(), lr=0.001)\n",
    "optimizer = optim.Adam(forward_model.parameters(), lr=0.001, weight_decay=1e-5)  # L2 regularization\n",
    "loss_values, validation_loss, testing_loss = [], [], []\n",
    "\n",
    "# Training the neural network\n",
    "num_epochs = 5000 #30000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = forward_model(X_train_tensor)\n",
    "    loss = criterion(outputs, Y_train_tensor)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Store the loss value\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "    # Validation phase (assume X_val_tensor and Y_val_tensor are defined for validation data)\n",
    "    forward_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = forward_model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, Y_val_tensor).item()\n",
    "        validation_loss.append(val_loss)\n",
    "\n",
    "        test_outputs = forward_model(X_test_tensor)\n",
    "        test_loss = criterion(test_outputs, Y_test_tensor).item()\n",
    "        testing_loss.append(test_loss)\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights after training\n",
    "#torch.save(forward_model.state_dict(), 'forward_model_weights_5000_iteration0.pth')\n",
    "print(\"Model weights saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    Y_pred = forward_model(X_test_tensor)\n",
    "    mse = mean_squared_error(Y_test_tensor.cpu().numpy(), Y_pred.cpu().numpy())\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(Y_test_tensor.cpu().numpy(), Y_pred.cpu().numpy())\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "    # Calculate Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "    # Calculate R-squared (R^2)\n",
    "    r2 = r2_score(Y_test_tensor.cpu().numpy(), Y_pred.cpu().numpy())\n",
    "    print(\"R-squared (R^2):\", r2)\n",
    "\n",
    "    # Calculate Mean Absolute Percentage Error (MAPE)\n",
    "    mape = np.mean(np.abs((Y_test_tensor.cpu().numpy() - Y_pred.cpu().numpy()) / Y_test_tensor.cpu().numpy())) * 100\n",
    "    print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "\n",
    "# Fix weights for forward model\n",
    "for param in forward_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Plot the loss function\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Adjust tick font sizes\n",
    "ax.tick_params(axis='both', which='major', labelsize=18)  # Change fontsize for major ticks\n",
    "ax.tick_params(axis='both', which='minor', labelsize=18)  # Optional: Change fontsize for minor ticks\n",
    "\n",
    "#plt.xlim(-0.1, 5000)\n",
    "\n",
    "# Remove the top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.plot(range(num_epochs), loss_values, label='Training Loss', color = 'dodgerblue')\n",
    "plt.plot(range(num_epochs), testing_loss, label='Testing Loss', color = 'orange')\n",
    "plt.plot(range(num_epochs), validation_loss, label='Validation Loss', color = 'green')\n",
    "#plt.plot(np.arange(0, 3530, 1), loss_values, label='Training Loss')\n",
    "#plt.plot(np.arange(0, 3530, 1), validation_loss, label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "#plt.title('Loss Function over Epochs')\n",
    "plt.legend(fontsize=18)\n",
    "plt.savefig('Supplementary3.png', transparent = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix weights for forward model\n",
    "for param in forward_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = forward_model(X_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the best-fit lines\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotting for each dimension in Y\n",
    "for i in range(Y_train_tensor.cpu().numpy().shape[1]):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.scatter(Y_train_tensor.cpu().numpy()[:, i], Y_pred.cpu().numpy()[:, i], color='dodgerblue')\n",
    "    plt.plot([min(Y_train_tensor.cpu().numpy()[:, i]), max(Y_train_tensor.cpu().numpy()[:, i])], [min(Y_train_tensor.cpu().numpy()[:, i]), max(Y_train_tensor.cpu().numpy()[:, i])], color='black', linestyle='--')\n",
    "    plt.xlabel('Actual Y')\n",
    "    plt.ylabel('Predicted Y')\n",
    "    #plt.title(f'Dimension {i+1}')\n",
    "\n",
    "    # Set tick font sizes\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    if i == 0:\n",
    "        plt.xlim(0, 6)\n",
    "        plt.ylim(0, 6)\n",
    "    else:\n",
    "        plt.xlim(0, 0.6)\n",
    "        plt.ylim(0, 0.6)\n",
    "    \n",
    "    r2 = r2_score(Y_train_tensor.cpu().numpy()[:, i], Y_pred.cpu().numpy()[:, i])\n",
    "    print(r2)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Supplementary3_1.png', transparent = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = forward_model(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the best-fit lines\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotting for each dimension in Y\n",
    "for i in range(Y_test_tensor.cpu().numpy().shape[1]):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.scatter(Y_test_tensor.cpu().numpy()[:, i], Y_pred.cpu().numpy()[:, i], color='orange')\n",
    "    plt.plot([min(Y_test_tensor.cpu().numpy()[:, i]), max(Y_test_tensor.cpu().numpy()[:, i])], [min(Y_test_tensor.cpu().numpy()[:, i]), max(Y_test_tensor.cpu().numpy()[:, i])], color='black', linestyle='--')\n",
    "    plt.xlabel('Actual Y')\n",
    "    plt.ylabel('Predicted Y')\n",
    "    #plt.title(f'Dimension {i+1}')\n",
    "\n",
    "    # Set tick font sizes\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "\n",
    "    if i == 0:\n",
    "        plt.xlim(0, 6)\n",
    "        plt.ylim(0, 6)\n",
    "    else:\n",
    "        plt.xlim(0, 0.6)\n",
    "        plt.ylim(0, 0.6)\n",
    "\n",
    "    r2 = r2_score(Y_test_tensor.cpu().numpy()[:, i], Y_pred.cpu().numpy()[:, i])\n",
    "    print(r2)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Supplementary3_2.png', transparent = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Loop through each vector and plot its probability density\n",
    "\n",
    "relative_error_PS = []\n",
    "relative_error_SED = []\n",
    "\n",
    "for j in range(Y_pred.shape[0]):\n",
    "\n",
    "    # Calculate the relative error for the i-th vector\n",
    "    relative_error_PS.append(np.abs(Y_pred[j][0].cpu() - Y_test_tensor[j][0].cpu()) / Y_test_tensor[j][0].cpu())\n",
    "    relative_error_SED.append(np.abs(Y_pred[j][1].cpu() - Y_test_tensor[j][1].cpu()) / Y_test_tensor[j][1].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the probability density\n",
    "\n",
    "density = gaussian_kde(relative_error_PS)\n",
    "x = np.linspace(0, np.max(relative_error_PS), 1000)\n",
    "\n",
    "# Plot the probability density\n",
    "plt.plot(x, density(x), label=f'Vector {i+1}')\n",
    "\n",
    "# Calculate %RE less than 10%\n",
    "samples1, samples2, samples3 = 0, 0, 0\n",
    "samples1 += len([ele for ele in relative_error_PS if ele < 0.10])\n",
    "samples2 += len([ele for ele in relative_error_PS if ele < 0.20])\n",
    "samples3 += len([ele for ele in relative_error_PS if ele < 0.30])\n",
    "\n",
    "\n",
    "print(samples1/(Y_pred.shape[0]))\n",
    "print(samples2/(Y_pred.shape[0]))\n",
    "print(samples3/(Y_pred.shape[0]))\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Probability Density vs. Relative Error for Multiple Vectors')\n",
    "plt.xlabel('Relative Error')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the probability density\n",
    "\n",
    "density = gaussian_kde(relative_error_SED)\n",
    "x = np.linspace(0, np.max(relative_error_SED), 1000)\n",
    "\n",
    "# Plot the probability density\n",
    "plt.plot(x, density(x), label=f'Vector {i+1}')\n",
    "\n",
    "# Calculate %RE less than 10%\n",
    "samples1, samples2, samples3 = 0, 0, 0\n",
    "samples1 += len([ele for ele in relative_error_SED if ele < 0.10])\n",
    "samples2 += len([ele for ele in relative_error_SED if ele < 0.20])\n",
    "samples3 += len([ele for ele in relative_error_SED if ele < 0.30])\n",
    "\n",
    "\n",
    "print(samples1/(Y_pred.shape[0]))\n",
    "print(samples2/(Y_pred.shape[0]))\n",
    "print(samples3/(Y_pred.shape[0]))\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Probability Density vs. Relative Error for Multiple Vectors')\n",
    "plt.xlabel('Relative Error')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
